# Cogworks Testing Framework Configuration
# Defines success thresholds, grading weights, and test composition rules

version: "1.0.0"

# Success Criteria Thresholds
thresholds:
  # Overall weighted score required to pass
  overall_minimum: 0.85

  # Synthesis quality (cogworks-encode output)
  synthesis:
    concept_count:
      min: 5
      max: 10
      warning_below: 7
    pattern_count:
      min: 5
      max: 10
      warning_below: 7
    tldr_length:
      min: 50 # words
      max: 150
    citation_coverage: 0.95 # 95% of claims must be traceable

  # Skill structure (cogworks-learn output)
  skill:
    skill_md_max_lines: 500
    supporting_file_threshold: 3 # minimum entries to justify separate file
    description_min_keywords: 3
    frontmatter_required_fields:
      - name
      - description

  # LLM-as-judge scores (1-5 scale)
  llm_judge:
    minimum_average: 4.0
    critical_minimum: 3.0 # any category below this is critical failure

  # Calibration (human-LLM agreement)
  calibration:
    target_agreement: 0.90 # 90% agreement within 0.5 points
    sample_size: 20

# Quality Dimension Weights (must sum to 1.0)
# Aligned with CLAUDE.md quality requirements
weights:
  source_fidelity: 0.30
  self_sufficiency: 0.25
  completeness: 0.20
  specificity: 0.15
  no_overlap: 0.10

# Test Dataset Composition Rules
# From skill-evaluation methodology
test_composition:
  explicit_examples: 0.50 # Clear, positive test cases
  implicit_patterns: 0.15 # Requires inference
  contextual_variations: 0.10 # Edge cases, variations
  negative_controls: 0.25 # Should NOT activate/pass

# Grading Layer Configuration
grading_layers:
  # Layer 1: Fast, cheap structural validation
  deterministic:
    enabled: true
    cost_per_test: 0.00001 # USD
    average_duration: 5 # seconds
    stop_on_critical: true # don't run Layer 2 if critical failures

  # Layer 2: LLM quality assessment
  llm_judge:
    enabled: true
    model: "claude-opus-4-6"
    cost_per_test: 1.50 # USD estimate
    average_duration: 45 # seconds
    temperature: 0.0 # deterministic grading
    max_tokens: 4096

  # Layer 3: Human calibration (optional)
  human_review:
    enabled: false # opt-in only
    cost_per_test: 100.00 # USD (expert time)
    average_duration: 1200 # seconds (20 minutes)

# Critical Failure Conditions
# Any of these conditions triggers immediate failure regardless of weighted score
critical_failures:
  - missing_frontmatter
  - invalid_yaml_frontmatter
  - no_source_citations
  - skill_md_exceeds_500_lines
  - fabricated_claims # claims not traceable to sources
  - security_vulnerabilities # command injection, etc.
  - hardcoded_sensitive_data # API keys, passwords

# Warning Conditions
# These don't fail tests but should be reported to user
warnings:
  - concept_count_below_target
  - pattern_count_below_target
  - missing_examples
  - sparse_coverage # less than 80% of source material used
  - potential_overlap_with_builtins
  - supporting_file_below_threshold # <3 entries in separate file

# Test Execution Settings
execution:
  timeout: 120 # seconds per test
  parallel_tests: false # run sequentially for now
  save_intermediate_outputs: true
  verbose_logging: false

# Result Storage
results:
  retention_days: 90
  format: ["json", "markdown"]
  include_timestamps: true
  git_friendly: true # use stable formatting for diffs
